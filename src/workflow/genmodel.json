{
  "238": {
    "inputs": {
      "base64_data": "",
      "image_output": "Hide",
      "save_prefix": "ComfyUI"
    },
    "class_type": "easy loadImageBase64",
    "_meta": {
      "title": "Load Image (Base64)"
    }
  },
  "239": {
    "inputs": {
      "base64_data": "",
      "image_output": "Hide",
      "save_prefix": "ComfyUI"
    },
    "class_type": "easy loadImageBase64",
    "_meta": {
      "title": "Load Image (Base64)"
    }
  },
  "240": {
    "inputs": {
      "base64_data": "",
      "image_output": "Hide",
      "save_prefix": "ComfyUI"
    },
    "class_type": "easy loadImageBase64",
    "_meta": {
      "title": "Load Image (Base64)"
    }
  },
  "273": {
    "inputs": {
      "channel": "red",
      "image": [
        "240",
        0
      ]
    },
    "class_type": "ImageToMask",
    "_meta": {
      "title": "Convert Image to Mask"
    }
  },
  "275": {
    "inputs": {
      "positive": [
        "307",
        0
      ],
      "negative": [
        "307",
        1
      ],
      "vae": [
        "276",
        2
      ],
      "pixels": [
        "238",
        0
      ],
      "mask": [
        "273",
        0
      ]
    },
    "class_type": "InpaintModelConditioning",
    "_meta": {
      "title": "InpaintModelConditioning"
    }
  },
  "276": {
    "inputs": {
      "ckpt_name": "epicrealism_naturalSinRC1VAE.safetensors"
    },
    "class_type": "CheckpointLoaderSimple",
    "_meta": {
      "title": "Load Checkpoint"
    }
  },
  "277": {
    "inputs": {
      "text": "human skin",
      "clip": [
        "276",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "Model Prompt"
    }
  },
  "278": {
    "inputs": {
      "text": "cartoon, painting, illustration, (worst quality, low quality, normal quality:2), garments, clothes, hat, cap",
      "clip": [
        "276",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "279": {
    "inputs": {
      "seed": 880712160035633,
      "steps": 20,
      "cfg": 5,
      "sampler_name": "dpmpp_2m_sde_gpu",
      "scheduler": "karras",
      "denoise": 0.6,
      "model": [
        "276",
        0
      ],
      "positive": [
        "275",
        0
      ],
      "negative": [
        "275",
        1
      ],
      "latent_image": [
        "275",
        2
      ]
    },
    "class_type": "KSampler",
    "_meta": {
      "title": "KSampler"
    }
  },
  "280": {
    "inputs": {
      "samples": [
        "279",
        0
      ],
      "vae": [
        "276",
        2
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "282": {
    "inputs": {
      "detect_hand": "enable",
      "detect_body": "enable",
      "detect_face": "enable",
      "resolution": 512,
      "scale_stick_for_xinsr_cn": "disable",
      "image": [
        "238",
        0
      ]
    },
    "class_type": "OpenposePreprocessor",
    "_meta": {
      "title": "OpenPose Pose"
    }
  },
  "284": {
    "inputs": {
      "control_net_name": "control_v11p_sd15_openpose_fp16.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "285": {
    "inputs": {
      "strength": 1,
      "start_percent": 0.5,
      "end_percent": 1,
      "positive": [
        "277",
        0
      ],
      "negative": [
        "278",
        0
      ],
      "control_net": [
        "284",
        0
      ],
      "image": [
        "282",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "286": {
    "inputs": {
      "strength": 0.55,
      "start_percent": 0.5,
      "end_percent": 1,
      "positive": [
        "285",
        0
      ],
      "negative": [
        "285",
        1
      ],
      "control_net": [
        "287",
        0
      ],
      "image": [
        "288",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "287": {
    "inputs": {
      "control_net_name": "controlnet++_canny_sd15_fp16.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "288": {
    "inputs": {
      "low_threshold": 0.1,
      "high_threshold": 0.2,
      "image": [
        "239",
        0
      ]
    },
    "class_type": "Canny",
    "_meta": {
      "title": "Canny"
    }
  },
  "289": {
    "inputs": {
      "da_model": [
        "290",
        0
      ],
      "images": [
        "239",
        0
      ]
    },
    "class_type": "DepthAnything_V2",
    "_meta": {
      "title": "Depth Anything V2"
    }
  },
  "290": {
    "inputs": {
      "model": "depth_anything_v2_vits_fp16.safetensors"
    },
    "class_type": "DownloadAndLoadDepthAnythingV2Model",
    "_meta": {
      "title": "DownloadAndLoadDepthAnythingV2Model"
    }
  },
  "291": {
    "inputs": {
      "strength": 0.5,
      "start_percent": 0.5,
      "end_percent": 0.8,
      "positive": [
        "286",
        0
      ],
      "negative": [
        "286",
        1
      ],
      "control_net": [
        "292",
        0
      ],
      "image": [
        "289",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "292": {
    "inputs": {
      "control_net_name": "controlnet++_depth_sd15_fp16.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "302": {
    "inputs": {
      "x": 0,
      "y": 0,
      "resize_source": false,
      "destination": [
        "239",
        0
      ],
      "source": [
        "280",
        0
      ],
      "mask": [
        "338",
        0
      ]
    },
    "class_type": "ImageCompositeMasked",
    "_meta": {
      "title": "ImageCompositeMasked"
    }
  },
  "305": {
    "inputs": {
      "filename_prefix": "genmodel",
      "images": [
        "302",
        0
      ]
    },
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Image"
    }
  },
  "306": {
    "inputs": {
      "control_net_name": "control_v11p_sd15_inpaint_fp16.safetensors"
    },
    "class_type": "ControlNetLoader",
    "_meta": {
      "title": "Load ControlNet Model"
    }
  },
  "307": {
    "inputs": {
      "strength": 0.4,
      "start_percent": 0.2,
      "end_percent": 0.9,
      "positive": [
        "291",
        0
      ],
      "negative": [
        "291",
        1
      ],
      "control_net": [
        "306",
        0
      ],
      "image": [
        "308",
        0
      ]
    },
    "class_type": "ControlNetApplyAdvanced",
    "_meta": {
      "title": "Apply ControlNet"
    }
  },
  "308": {
    "inputs": {
      "black_pixel_for_xinsir_cn": false,
      "image": [
        "238",
        0
      ],
      "mask": [
        "273",
        0
      ]
    },
    "class_type": "InpaintPreprocessor",
    "_meta": {
      "title": "Inpaint Preprocessor"
    }
  },
  "338": {
    "inputs": {
      "expand": 1,
      "incremental_expandrate": 0,
      "tapered_corners": false,
      "flip_input": false,
      "blur_radius": 0.5,
      "lerp_alpha": 1,
      "decay_factor": 1,
      "fill_holes": false,
      "mask": [
        "273",
        0
      ]
    },
    "class_type": "GrowMaskWithBlur",
    "_meta": {
      "title": "Grow Mask With Blur"
    }
  }
}